---
title: "EP-11"
date: "2023-07-06"
output: html_document
---

```{r setup, include=FALSE}
library(car)
library(leaps)
library(tidyverse)
library(caret)
```

## Datos

A continuación se obtendran los datos necesarios para los modelos en cuestión:

```{r datos}
data <- read.csv2("EP09 Datos.csv", stringsAsFactors = TRUE) # Se lee el archivo

IMC <- data$Weight / ((data$Height / 100) ** 2)  # Se pasa la altura de centimetros a metros y se calcula IMC
EN <- ifelse(IMC > 25, 1, 0) # Se inicia un vector dicotomico  (1: Sobrepeso, 0: No sobrepeso)

data <- data.frame(data, EN, IMC)
sobrepeso <- subset(data, EN == 1)
noSobrepeso <- subset(data, EN == 0)
```

## Pasos a seguir

Ahora podemos construir un modelo de regresión logística para predecir la variable EN, de acuerdo con las siguientes instrucciones:

1.Definir la semilla a utilizar, que corresponde a los primeros cinco dígitos del RUN del integrante de mayor edad del equipo.

2.Seleccionar una muestra de 100 personas, asegurando que la mitad tenga estado nutricional “sobrepeso” y la otra mitad “no sobrepeso”.

3.Usando las herramientas del paquete leaps, realizar una búsqueda exhaustiva para seleccionar entre dos y ocho predictores que ayuden a estimar la variable Peso (Weight), obviamente sin considerar las nuevas variables IMC ni EN, y luego utilizar las funciones del paquete caret para construir un modelo de regresión lineal múltiple con los predictores escogidos y evaluarlo usando bootstrapping.

4. Haciendo un poco de investigación sobre el paquete caret, en particular cómo hacer Recursive Feature Elimination (RFE), construir un modelo de regresión lineal múltiple para predecir la variable IMC que incluya entre 10 y 20 predictores, seleccionando el conjunto de variables que maximice R2 y que use cinco repeticiones de validación cruzada de cinco pliegues para evitar el sobreajuste (obviamente no se debe considerar las variables Peso, Estatura ni estado nutricional –Weight, Height, EN respectivamente).

5. Usando RFE, construir un modelo de regresión logística múltiple para la variable EN que incluya el conjunto, de entre dos y seis, predictores que entregue la mejor curva ROC y que utilice validación cruzada dejando uno fuera para evitar el sobreajuste (obviamente no se debe considerar las variables Peso, Estatura –Weight y Height respectivamente– ni IMC).

6. Pronunciarse sobre la confiabilidad y el poder predictivo de los modelos obtenidos.

# Solución

## Muestra

Se utilizará la semilla 20051 para asegurar la posibilidad reproducir estudio, se sacará una muestra de 100 hombres, de los cuales la mitad tiene un estado nutricional "sobrepeso" y la otra mitad "no sobrepeso"

```{r muestras}
set.seed(20051) # Se define la semilla según el rut del miembro mayor (primeros 5 digitos antes del digito verificador)

# Se toma una muestra de 100 con 50 en sobrepeso y 50 que no
muestra <- merge(sample_n(sobrepeso, 50), sample_n(noSobrepeso, 50), all = TRUE)  

sobrepeso <- subset(muestra, EN == 1)
noSobrepeso <- subset(muestra, EN == 0)

muestra = rbind(noSobrepeso, sobrepeso)
EN_cor = muestra[["EN"]]
en_muestra = factor(muestra[["EN"]])
muestra[["EN"]] = NULL
IMC_muestra = muestra[["IMC"]]
muestra[["IMC"]] = NULL
```

## Modelo de regresión lineal múltiple para la variable peso

### Selección de predictores para el modelo

```{r seleccion predictores}
set.seed(20051)
predictores = regsubsets(Weight~.,
                         data=muestra,
                         nbest=1,
                         nvmax=8,
                         method="exhaustive")
plot(predictores)
```

Como se puede notar el modelo con menor bic es el que incluye Knees.diameter, Chest.Girth, Waist.Girth, Thigh.Girth, Navel.Girth, Calf.Maximum.Girth, Age, Height, por lo que son los seleccionados
para el modelo

### Ajuste del modelo

```{r ajuste del modelo}
set.seed(20051)
predictores_seleccionados = muestra %>% select(Weight, Knees.diameter, Chest.Girth, Waist.Girth, Thigh.Girth, Navel.Girth, Calf.Maximum.Girth, Age, Height)
modelo_peso = train(Weight ~ ., 
               data = predictores_seleccionados, method="lm", trControl = trainControl(method = "boot", number = 2999))
print(summary(modelo_peso))
```
El modelo_peso que se obtiene posee un R^2 adjustado de 0.968, lo que quiere decir que el modelo explica el 96.8% de la variabilidad de los datos. Se calcula entonces la calidad predictiva del modelo

```{r prediccion & rmse}
# Predicción del modelo
predicciones_peso = predict(modelo_peso, predictores_seleccionados)
error_peso = muestra[["Weight"]] - predicciones_peso
# Error cuadratico del modelo (rmse)
error_cuadratico = sqrt(mean(error_peso ** 2))
error_cuadratico
```

Tenemos que el valor del error cuadrático para el modelo es de 2.347, lo que indica que los valores predichos se asemejan mucho a los valores observados, con lo que podemos decir que el modelo tiene una gran capacidad predictiva.

## Evaluacion de confiabilidad del modelo de regresión lineal múltiple

```{r confiabilidad rlm}
eval_rlm_peso = data.frame(predicted.probabilities = fitted(modelo_peso[["finalModel"]]))
eval_rlm_peso[["standardized.residuals"]] <- rstandard(modelo_peso[["finalModel"]])
eval_rlm_peso[["studentized.residuals"]] <- rstudent(modelo_peso[["finalModel"]])
eval_rlm_peso[["cooks.distance"]] <- cooks.distance(modelo_peso[["finalModel"]])
eval_rlm_peso[["dfbeta"]] <- dfbeta(modelo_peso[["finalModel"]])
eval_rlm_peso[["dffit"]] <- dffits(modelo_peso[["finalModel"]])
eval_rlm_peso[["leverage"]] <- hatvalues(modelo_peso[["finalModel"]])
eval_rlm_peso[["covariance.ratios"]] <- covratio(modelo_peso[["finalModel"]])

cat("Influencia de los casos:\n")

# 95% de los residuos estandarizados deberían estar entre −1.96 y +1.96, y 99%
# entre -2.58 y +2.58.
sospechosos1 <- which(abs(eval_rlm_peso[["standardized.residuals"]]) > 1.96)
cat("Residuos estandarizados fuera del 95% esperado: ")
print(sospechosos1)

# Observaciones con distancia de Cook mayor a uno.
sospechosos2 <- which(eval_rlm_peso[["cooks.distance"]] > 1)
cat("Residuos con distancia de Cook mayor que 1: ")
print(sospechosos2)

# Observaciones con apalancamiento mayor al doble del apalancamiento promedio: (k + 1)/n.
apalancamiento.promedio <- ncol(predictores_seleccionados) / nrow(predictores_seleccionados)
sospechosos3 <- which(eval_rlm_peso[["leverage"]] > 2 * apalancamiento.promedio)

cat("Residuos con leverage fuera de rango (promedio = ",
    apalancamiento.promedio, "): ", sep = "")

print(sospechosos3)

# DFBeta debería ser < 1.
sospechosos4 <- which(apply(eval_rlm_peso[["dfbeta"]] >= 1, 1, any))
names(sospechosos4) <- NULL
cat("Residuos con DFBeta mayor que 1: ")
print(sospechosos4)


CVRi.lower <- 1 - 3 * apalancamiento.promedio
CVRi.upper <- 1 + 3 * apalancamiento.promedio
sospechosos5 <- which(eval_rlm_peso[["covariance.ratios"]] < CVRi.lower |
                        eval_rlm_peso[["covariance.ratios"]] > CVRi.upper)

cat("Residuos con razón de covarianza fuera de rango ([", CVRi.lower, ", ",
    CVRi.upper, "]): ", sep = "")

print(sospechosos5)

sospechosos <- c(sospechosos1, sospechosos2, sospechosos3, sospechosos4,
                 sospechosos5)

sospechosos <- sort(unique(sospechosos))
cat("Observaciones sospechosas:\n")

print(round(eval_rlm_peso[sospechosos, c("cooks.distance", "leverage", "covariance.ratios")], 3))
```

Si bien hay algunas observaciones que podrían considerarse atípicas, la distancia de Cook para todas ellas se aleja bastante de 1, por lo que no deberían ser causa de preocupación.

## Modelo de regresión lineal múltiple para la variable IMC

```{r modelo_imc}
set.seed(20051)
# Se descartan las variables inútiles
imc_datos = muestra %>% select(-c(Height, Weight))
# Regresión escalonada
# Lmfuncs para regresión lineal
imc_control = rfeControl(functions = lmFuncs, method= "repeatedcv",
                         number = 5, repeats = 5, verbose = F)
# Sizes: Valores entre los cuales varía el número de predictores
# Metric: Métrica que se usa para comparar, en este caso, máximizar el R cuadrado
pred_imc = rfe(imc_datos, IMC_muestra, rfeControl = imc_control, sizes = 10:20, metric = "Rsquared")
print(pred_imc)
print(pred_imc[["optVariables"]])
predictores_imc <- pred_imc$optVariables
print(ggplot(pred_imc))
cat("Tenemos que el mejor modelo esta compuesto por 15 predictores, así que generaremos un modelo con estos predictores para evaluarlo")
predictores_seleccionados <- muestra %>% select(Gender, Knees.diameter, Calf.Maximum.Girth, Wrist.Minimum.Girth, Knee.Girth, Elbows.diameter, Ankles.diameter, Biiliac.diameter, Forearm.Girth, Bitrochanteric.diameter, Bicep.Girth, Waist.Girth, Wrists.diameter, Biacromial.diameter, Chest.Girth)

IMC <- muestra$Weight / ((muestra$Height / 100) ** 2)

imc_datos <- cbind(IMC, imc_datos)

modelo_imc <- train(IMC ~ Gender + Knees.diameter + Calf.Maximum.Girth + Wrist.Minimum.Girth + Knee.Girth + Elbows.diameter + Ankles.diameter + Biiliac.diameter + Forearm.Girth + Bitrochanteric.diameter + Bicep.Girth + Waist.Girth + Wrists.diameter + Biacromial.diameter + Chest.Girth, 
                    data = imc_datos, method = "lm", trControl = trainControl(method = "cv", number = 10))
modelo_imc
```

Como se puede observar, tenemos que el modelo entrega un Rsquared de 0.880, con lo que podemos concluir que el modelo se ajusta bien a los datos.

## Evaluacion de confiabilidad del modelo de regresión lineal múltiple para imc

```{r confiabilidad rlm2}
eval_rlm_imc = data.frame(predicted.probabilities = fitted(modelo_imc[["finalModel"]]))
eval_rlm_imc[["standardized.residuals"]] <- rstandard(modelo_imc[["finalModel"]])
eval_rlm_imc[["studentized.residuals"]] <- rstudent(modelo_imc[["finalModel"]])
eval_rlm_imc[["cooks.distance"]] <- cooks.distance(modelo_imc[["finalModel"]])
eval_rlm_imc[["dfbeta"]] <- dfbeta(modelo_imc[["finalModel"]])
eval_rlm_imc[["dffit"]] <- dffits(modelo_imc[["finalModel"]])
eval_rlm_imc[["leverage"]] <- hatvalues(modelo_imc[["finalModel"]])
eval_rlm_imc[["covariance.ratios"]] <- covratio(modelo_imc[["finalModel"]])

cat("Influencia de los casos:\n")

# 95% de los residuos estandarizados deberían estar entre −1.96 y +1.96, y 99%
# entre -2.58 y +2.58.
sospechosos1 <- which(abs(eval_rlm_imc[["standardized.residuals"]]) > 1.96)
cat("Residuos estandarizados fuera del 95% esperado: ")
print(sospechosos1)

# Observaciones con distancia de Cook mayor a uno.
sospechosos2 <- which(eval_rlm_imc[["cooks.distance"]] > 1)
cat("Residuos con distancia de Cook mayor que 1: ")
print(sospechosos2)

# Observaciones con apalancamiento mayor al doble del apalancamiento promedio: (k + 1)/n.
apalancamiento.promedio <- ncol(predictores_seleccionados) / nrow(predictores_seleccionados)
sospechosos3 <- which(eval_rlm_peso[["leverage"]] > 2 * apalancamiento.promedio)

cat("Residuos con leverage fuera de rango (promedio = ",
    apalancamiento.promedio, "): ", sep = "")

print(sospechosos3)

# DFBeta debería ser < 1.
sospechosos4 <- which(apply(eval_rlm_imc[["dfbeta"]] >= 1, 1, any))
names(sospechosos4) <- NULL
cat("Residuos con DFBeta mayor que 1: ")
print(sospechosos4)


CVRi.lower <- 1 - 3 * apalancamiento.promedio
CVRi.upper <- 1 + 3 * apalancamiento.promedio
sospechosos5 <- which(eval_rlm_imc[["covariance.ratios"]] < CVRi.lower |
                        eval_rlm_imc[["covariance.ratios"]] > CVRi.upper)

cat("Residuos con razón de covarianza fuera de rango ([", CVRi.lower, ", ",
    CVRi.upper, "]): ", sep = "")

print(sospechosos5)

sospechosos <- c(sospechosos1, sospechosos2, sospechosos3, sospechosos4,
                 sospechosos5)

sospechosos <- sort(unique(sospechosos))
cat("Observaciones sospechosas:\n")

print(round(eval_rlm_imc[sospechosos, c("cooks.distance", "leverage", "covariance.ratios")], 3))
```

Si bien hay algunas observaciones que podrían considerarse atípicas, la distancia de Cook para todas ellas se aleja bastante de 1, siendo la máxima de 0.141, por lo que no deberían ser causa de preocupación.

## Modelo de regresión logística múltiple para la variable EN

```{r en_glm}
set.seed(20051)
# Agregamos twoClassSummary a las funciones de lrFuncs para poder usar la métrica ROC 
lrFuncs$summary <- twoClassSummary
# (Knees.diameter, Elbows.diameter, Thigh.Girth, Chest.Girth, Calf.Maximum.Girth, Ankles.diameter)
en_datos = muestra %>% select(-c(Height, Weight))
en_control = rfeControl(functions = lrFuncs, method = "LOOCV", number = 1, verbose = F)
# Construcción del objeto para evaluar el rendimiento del modelo (con la curva ROC)
en_entrenamiento = trainControl(method = "none", classProbs = T, summaryFunction = twoClassSummary)

modelo_en = rfe(en_datos, en_muestra, metric = "ROC", rfeControl = en_control, sizes = 2:6, trControl = en_entrenamiento)

print(modelo_en)
print(ggplot(modelo_en))
cat("Si bien, la construcción del modelo nos entrega múltiples advertencias 'Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred', esto ocurre durante la construcción del modelo a través de 'RFE' sin embargo, tenemos que el modelo que alcanza el valor más alto para la métrica ROC es con 5 variables predictoras.")
pred_imc = predict(modelo_en, en_datos)[["pred"]]
print(confusionMatrix(pred_imc, en_muestra))
```


Construímos un modelo con estas 5 mejores variables, las cuales son: Chest.Girth, Gender, Knee.Girth, Elbows.diameter, Ankles.diameter. Este modelo no entrega estas advertencias, con lo cual no tenemos problemas con probabilidades peligrosas.

```{r modelo glm}
set.seed(20051)
glm_predictor <- muestra %>% select(Chest.Girth, Gender, Knee.Girth, Elbows.diameter, Ankles.diameter, Calf.Maximum.Girth)
glm_datos <- cbind(glm_predictor, en_muestra)
glm_en <- train(en_muestra ~ ., data = glm_datos, method = "glm", family = "binomial", control = glm.control(maxit = 2999))
print("Resumen del modelo:")
print(summary(glm_en))
```

El gráfico muestra que el área bajo la curva ROC se maximiza para 6 variables, con un valor de 88,24% (78,0% de sensibilidad y 82,0% de especificidad).

Además, podemos ver que el modelo tiene una exactitud del 89% por lo que se ajusta bien a los datos.

## Evaluación de confiabilidad del modelo de regresión logística múltiple para la variable EN

```{r evaluacion glm}
eval_glm_en = data.frame(predicted.probabilities = fitted(glm_en[["finalModel"]]))
eval_glm_en[["standardized.residuals"]] <- rstandard(glm_en[["finalModel"]])
eval_glm_en[["studentized.residuals"]] <- rstudent(glm_en[["finalModel"]])
eval_glm_en[["cooks.distance"]] <- cooks.distance(glm_en[["finalModel"]])
eval_glm_en[["dfbeta"]] <- dfbeta(glm_en[["finalModel"]])
eval_glm_en[["dffit"]] <- dffits(glm_en[["finalModel"]])
eval_glm_en[["leverage"]] <- hatvalues(glm_en[["finalModel"]])
eval_glm_en[["covariance.ratios"]] <- covratio(glm_en[["finalModel"]])

cat("Influencia de los casos:\n")

# 95% de los residuos estandarizados deberían estar entre −1.96 y +1.96, y 99%
# entre -2.58 y +2.58.
sospechosos1 <- which(abs(eval_glm_en[["standardized.residuals"]]) > 1.96)
cat("Residuos estandarizados fuera del 95% esperado: ")
print(sospechosos1)

# Observaciones con distancia de Cook mayor a uno.
sospechosos2 <- which(eval_glm_en[["cooks.distance"]] > 1)
cat("Residuos con distancia de Cook mayor que 1: ")
print(sospechosos2)

# Observaciones con apalancamiento mayor al doble del apalancamiento promedio: (k + 1)/n.
apalancamiento.promedio <- ncol(predictores_seleccionados) / nrow(predictores_seleccionados)
sospechosos3 <- which(eval_glm_en[["leverage"]] > 2 * apalancamiento.promedio)

cat("Residuos con leverage fuera de rango (promedio = ",
    apalancamiento.promedio, "): ", sep = "")

print(sospechosos3)

# DFBeta debería ser < 1.
sospechosos4 <- which(apply(eval_glm_en[["dfbeta"]] >= 1, 1, any))
names(sospechosos4) <- NULL
cat("Residuos con DFBeta mayor que 1: ")
print(sospechosos4)


CVRi.lower <- 1 - 3 * apalancamiento.promedio
CVRi.upper <- 1 + 3 * apalancamiento.promedio
sospechosos5 <- which(eval_glm_en[["covariance.ratios"]] < CVRi.lower |
                        eval_glm_en[["covariance.ratios"]] > CVRi.upper)

cat("Residuos con razón de covarianza fuera de rango ([", CVRi.lower, ", ",
    CVRi.upper, "]): ", sep = "")

print(sospechosos5)

sospechosos <- c(sospechosos1, sospechosos2, sospechosos3, sospechosos4,
                 sospechosos5)

sospechosos <- sort(unique(sospechosos))
cat("Observaciones sospechosas:\n")

print(round(eval_glm_en[sospechosos, c("cooks.distance", "leverage", "covariance.ratios")], 3))
```

Si bien hay algunas observaciones que podrían considerarse atípicas, la distancia de Cook para todas ellas se aleja bastante de 1, por lo que no deberían ser causa de preocupación.