install.packages("rmarkdown")
install.packages("markdown")
install.packages("knitr")
install.packages(c("boot", "car", "caret", "dplyr", "ggplot2", "ggpubr", "grid", "gridExtra", "gmodels", "ez", "emmeans", "infer", "kableExtra", "Hmisc", "knitr", "leaps", "lmtest", "lsmeans", "MASS", "multcomp", "nlme", "plyr", "purrr", "pwr", "readr", "scatterplot3d", "TeachingDemos", "tibble", "tidyr", "xlsx"))
install.packages(c("boot", "car", "caret", "dplyr", "ggplot2", "ggpubr", "grid", "gridExtra", "gmodels", "ez", "emmeans", "infer", "kableExtra", "Hmisc", "knitr", "leaps", "lmtest", "lsmeans", "MASS", "multcomp", "nlme", "plyr", "purrr", "pwr", "readr", "scatterplot3d", "TeachingDemos", "tibble", "tidyr", "xlsx"))
install.packages("ggpubr")
install.packages("car")
install.packages("nloptr")
install.packages("nloptr")
install.packages("ggpubr")
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("RVAideMemoire")
install.packages("mixOmics")
devtools::install_github("mixOmicsTeam/mixOmics")
install.packages("devtools")
devtools::install_github("mixOmicsTeam/mixOmics")
install.packages("RVAideMemoire")
install.packages(c("boot", "car", "caret", "dplyr", "ggplot2", "ggpubr", "grid", "gridExtra", "gmodels", "ez", "emmeans", "infer", "kableExtra", "Hmisc", "knitr", "leaps", "lmtest", "lsmeans", "MASS", "multcomp", "nlme", "plyr", "purrr", "pwr", "readr", "scatterplot3d", "TeachingDemos", "tibble", "tidyr", "xlsx"))
library(tidyverse)
library(pROC)
library(caret)
library(leaps)
library(car)
setwd("C:/Users/Matias/Downloads")
setwd("~/Documentos/Estadistica_inferencial/EP-10")
library(tidyverse)
library(pROC)
library(caret)
library(leaps)
library(car)
# 1. Definir la semilla a utilizar, que corresponde a los últimos cuatro dígitos del RUN (sin considerar el dígito verificador) del integrante de mayor edad del equipo.
set.seed(1667)
datos <- read.csv2("EP09 Datos.csv")
# 2. Seleccionar una muestra de 90 mujeres (si la semilla es un número par) o 90 hombres (si la semilla es impar), asegurando que la mitad tenga estado nutricional “sobrepeso” y la otra mitad “no sobrepeso” en cada caso. Dividir esta muestra en dos conjuntos: los datos de 60 personas (30 con EN “sobrepeso”) para utilizar en la construcción de los modelos y 30 personas (15 con EN “sobrepeso”) para poder evaluarlos.
# Variable IMC -> Kilogramos / Estatura^2 (Estatura en metros, en csv está en centimetros)
IMC <- datos[["Weight"]] / ((datos[["Height"]] / 100) ** 2)
# Construimos la variable dicotómica EN (Estado Nutricional) para sobrepeso (IMC >= 25) y no sobrepeso (IMC < 25)
EN <- rep("Sobrepeso", length(IMC))
EN[IMC < 25] <- "No sobrepeso"
EN <- factor(EN)
datos <- cbind(EN, datos)
# Obtenemos solo los hombres y eliminamos la columna Gender (inutil de acá en adelante)
datos <- datos %>% filter(datos$Gender == 1)
datos[["Gender"]] <- NULL
# Obtenemos mitad sobrepeso y mitad no sobrepeso (45 y 45, total 90)
sobrepeso <- filter(datos, EN == "Sobrepeso")
sobrepeso <- sample_n(sobrepeso, 45, replace = FALSE)
no_sobrepeso <- datos %>% filter(EN == "No sobrepeso")
no_sobrepeso <- sample_n(no_sobrepeso, 45, replace = FALSE)
# Separamos por conjuntos de entrenamiento y de prueba
sobrepeso_1 <- sample.int(nrow(sobrepeso), 30, replace = FALSE)
no_sobrepeso_1 <- sample.int(nrow(no_sobrepeso), 30, replace = FALSE)
entrenamiento_sobrepeso <- sobrepeso[sobrepeso_1,] # 30 sobrepeso
entrenamiento_no_sobrepeso <- no_sobrepeso[no_sobrepeso_1,] # 30 no sobrepeso
prueba_sobrepeso <- sobrepeso[-sobrepeso_1,] # restante (15) sobrepeso
prueba_no_sobrepeso <- no_sobrepeso[-no_sobrepeso_1,] # restante (15) no sobrepeso
entrenamiento <- rbind(entrenamiento_sobrepeso, entrenamiento_no_sobrepeso) # total 60
prueba <- rbind(prueba_sobrepeso, prueba_no_sobrepeso) # total 30
# 3. Recordar las ocho posibles variables predictoras seleccionadas de forma aleatoria en el ejercicio anterior.
# 4. Seleccionar, de las otras variables, una que el equipo considere que podría ser útil para predecir la clase EN, justificando bien esta selección.
# Para 3. -> Traemos las ocho variables predictoras del ejercicio anterior
# Para 4 -> Escogemos el peso como predictor para el modelo de RLogS ya que el peso se relaciona fuertemente con el IMC, el cual se usa para determinar sobrepeso
entrenamiento <- entrenamiento %>% select(EN, Biacromial.diameter, Calf.Maximum.Girth, Chest.depth, Bicep.Girth, Bitrochanteric.diameter, Age, Elbows.diameter, Hip.Girth, Weight)
prueba <- entrenamiento %>% select(EN, Biacromial.diameter, Calf.Maximum.Girth, Chest.depth, Bicep.Girth, Bitrochanteric.diameter, Age, Elbows.diameter, Hip.Girth, Weight)
# 5. Usando el entorno R y paquetes estándares, construir un modelo de regresión logística con el predictor seleccionado en el paso anterior y utilizando de la muestra obtenida.
# Usamos el modelo de regresión logistica simple con predictor peso y data de entrenamiento del punto anterior
rlogs <- glm(EN ~ Weight, data = entrenamiento,
family = binomial(link = "logit"))
summary(rlogs)
# Evaluamos la calidad predictiva del modelo anterior, con umbral de 0.5
umbral <- 0.5
probabilidades <- predict(rlogs, prueba, type = "response")
predicciones <- sapply(probabilidades,
function (p) ifelse (p >= umbral, "Sobrepeso", "No sobrepeso"))
predicciones <- factor(predicciones, levels = levels(prueba[["EN"]]))
confusionMatrix(predicciones, prueba[["EN"]])
# Podemos ver que el tiene una buena capacidad predictiva, con una exactitud de
# 80,0%, sensibilidad de 83,33% y especificidad de 76,67%.
# 6. Usando herramientas estándares para la exploración de modelos del entorno R, buscar entre dos y cinco predictores de entre las variables seleccionadas al azar, recordadas en el punto 3, para agregar al modelo obtenido en el paso 5.
# Seleccionamos los mejores predictores para el modelo de regresión lineal múltiple usando el método de todos los subconjuntos.
rlogm.inicial <- regsubsets(EN ~ ., data = entrenamiento, nbest = 1, nvmax = 5,
method = "exhaustive")
plot(rlogm.inicial)
# De acuerdo a la exploración de todos los subconjuntos, se obtiene que el mejor modelo
# entre 2 y 5 variables usa como predictores Calf.Maximum.Girth, Chest.depth, Bicep.Girth, Elbows.diameter y Hip.Girth
View(rlogs)
library(caret)
library(pROC)
library(tidyverse)
data <- read.csv2("EP09 Datos.csv", stringsAsFactors = TRUE) # Se lee el archivo
IMC <- data$Weight / ((data$Height / 100) ** 2)  # Se pasa la altura de centimetros a metros y se calcula IMC
EN <- ifelse(IMC > 25, 1, 0) # Se inicia un vector dicotomico  (1: Sobrepeso, 0: No sobrepeso)
data <- data.frame(data, EN)
hombres <- subset(data, Gender == 1)
hombres$Gender <- NULL
sobrepeso <- subset(hombres, EN == 1)
noSobrepeso <- subset(hombres, EN == 0)
set.seed(1667) # Se define la semilla según el rut del miembro mayor (ultimos 4 digitos antes del digito verificador)
# Se toma una muestra de 90 con 45 en sobrepeso y 45 que no
muestra <- merge(sample_n(sobrepeso, 45), sample_n(noSobrepeso, 45), all = TRUE)
sobrepeso <- subset(muestra, EN == 1)
noSobrepeso <- subset(muestra, EN == 0)
# Se obtiene una submuestra de 60 con 30 en sobrepeso y 30 que no para el entrenamiento del modelo
entrenamiento <- merge(sample_n(sobrepeso, 30), sample_n(noSobrepeso, 30), all = TRUE)
# De la muestra original (de 90) se toman los datos restantes (que no son destinados al entrenamiento), para usarlos para la proxima evaluacion del modelo
evaluacion <- anti_join(muestra, entrenamiento, by = names(muestra))
predictores <- c("Biacromial.diameter", "Calf.Maximum.Girth", "Chest.depth", "Bicep.Girth", "Bitrochanteric.diameter", "Age", "Elbows.diameter", "Hip.Girth")
respuesta <- entrenamiento[["EN"]]
entrenamiento[["EN"]] <- NULL
matriz <- entrenamiento %>% select(-any_of(predictores))
correlacion <- cor(matriz, y = respuesta)
correlacion
mejor <- which(correlacion == max(abs(correlacion)))
predictor <- rownames(correlacion)[mejor]
predictor
modelo_1 <- glm(respuesta ~ Navel.Girth, family = binomial(link = "logit"), data = entrenamiento)
library(caret)
library(pROC)
library(tidyverse)
data <- read.csv2("EP09 Datos.csv", stringsAsFactors = TRUE) # Se lee el archivo
IMC <- data$Weight / ((data$Height / 100) ** 2)  # Se pasa la altura de centimetros a metros y se calcula IMC
EN <- ifelse(IMC > 25, 1, 0) # Se inicia un vector dicotomico  (1: Sobrepeso, 0: No sobrepeso)
data <- data.frame(data, EN)
hombres <- subset(data, Gender == 1)
hombres$Gender <- NULL
sobrepeso <- subset(hombres, EN == 1)
noSobrepeso <- subset(hombres, EN == 0)
set.seed(1667) # Se define la semilla según el rut del miembro mayor (ultimos 4 digitos antes del digito verificador)
# Se toma una muestra de 90 con 45 en sobrepeso y 45 que no
muestra <- merge(sample_n(sobrepeso, 45), sample_n(noSobrepeso, 45), all = TRUE)
sobrepeso <- subset(muestra, EN == 1)
noSobrepeso <- subset(muestra, EN == 0)
# Se obtiene una submuestra de 60 con 30 en sobrepeso y 30 que no para el entrenamiento del modelo
entrenamiento <- merge(sample_n(sobrepeso, 30), sample_n(noSobrepeso, 30), all = TRUE)
# De la muestra original (de 90) se toman los datos restantes (que no son destinados al entrenamiento), para usarlos para la proxima evaluacion del modelo
evaluacion <- anti_join(muestra, entrenamiento, by = names(muestra))
predictores <- c("Biacromial.diameter", "Calf.Maximum.Girth", "Chest.depth", "Bicep.Girth", "Bitrochanteric.diameter", "Age", "Elbows.diameter", "Hip.Girth")
respuesta <- entrenamiento[["EN"]]
entrenamiento[["EN"]] <- NULL
matriz <- entrenamiento %>% select(-any_of(predictores))
correlacion <- cor(matriz, y = respuesta)
correlacion
mejor <- which(correlacion == max(abs(correlacion)))
predictor <- rownames(correlacion)[mejor]
predictor
modelo_1 <- glm(respuesta ~ Navel.Girth, family = binomial(link = "logit"), data = entrenamiento)
modelo_1 <- glm(respuesta ~ Navel.Girth, family = binomial(link = "logit"), data = entrenamiento)
modelo_1
modelo_1 <- glm(respuesta ~ Navel.Girth, family = binomial(link = "logit"), data = entrenamiento)
6. Usando herramientas estándares1 para la exploración de modelos del entorno R, buscar entre dos y cinco predictores de entre las variables seleccionadas al azar, recordadas en el punto 3, para agregar al modelo obtenido en el paso 5.
# Seleccionamos los mejores predictores para el modelo de regresión lineal múltiple usando el método de todos los subconjuntos.
rlogm.inicial <- regsubsets(EN ~ ., data = entrenamiento, nbest = 1, nvmax = 5,
method = "exhaustive")
View(entrenamiento)
library(tidyverse)
library(pROC)
library(caret)
library(leaps)
library(car)
# 1. Definir la semilla a utilizar, que corresponde a los últimos cuatro dígitos del RUN (sin considerar el dígito verificador) del integrante de mayor edad del equipo.
set.seed(1667)
datos <- read.csv2("EP09 Datos.csv")
# 2. Seleccionar una muestra de 90 mujeres (si la semilla es un número par) o 90 hombres (si la semilla es impar), asegurando que la mitad tenga estado nutricional “sobrepeso” y la otra mitad “no sobrepeso” en cada caso. Dividir esta muestra en dos conjuntos: los datos de 60 personas (30 con EN “sobrepeso”) para utilizar en la construcción de los modelos y 30 personas (15 con EN “sobrepeso”) para poder evaluarlos.
# Variable IMC -> Kilogramos / Estatura^2 (Estatura en metros, en csv está en centimetros)
IMC <- datos[["Weight"]] / ((datos[["Height"]] / 100) ** 2)
# Construimos la variable dicotómica EN (Estado Nutricional) para sobrepeso (IMC >= 25) y no sobrepeso (IMC < 25)
EN <- rep("Sobrepeso", length(IMC))
EN[IMC < 25] <- "No sobrepeso"
EN <- factor(EN)
datos <- cbind(EN, datos)
# Obtenemos solo los hombres y eliminamos la columna Gender (inutil de acá en adelante)
datos <- datos %>% filter(datos$Gender == 1)
datos[["Gender"]] <- NULL
# Obtenemos mitad sobrepeso y mitad no sobrepeso (45 y 45, total 90)
sobrepeso <- filter(datos, EN == "Sobrepeso")
sobrepeso <- sample_n(sobrepeso, 45, replace = FALSE)
no_sobrepeso <- datos %>% filter(EN == "No sobrepeso")
no_sobrepeso <- sample_n(no_sobrepeso, 45, replace = FALSE)
# Separamos por conjuntos de entrenamiento y de prueba
sobrepeso_1 <- sample.int(nrow(sobrepeso), 30, replace = FALSE)
no_sobrepeso_1 <- sample.int(nrow(no_sobrepeso), 30, replace = FALSE)
entrenamiento_sobrepeso <- sobrepeso[sobrepeso_1,] # 30 sobrepeso
entrenamiento_no_sobrepeso <- no_sobrepeso[no_sobrepeso_1,] # 30 no sobrepeso
prueba_sobrepeso <- sobrepeso[-sobrepeso_1,] # restante (15) sobrepeso
prueba_no_sobrepeso <- no_sobrepeso[-no_sobrepeso_1,] # restante (15) no sobrepeso
entrenamiento <- rbind(entrenamiento_sobrepeso, entrenamiento_no_sobrepeso) # total 60
prueba <- rbind(prueba_sobrepeso, prueba_no_sobrepeso) # total 30
# 3. Recordar las ocho posibles variables predictoras seleccionadas de forma aleatoria en el ejercicio anterior.
# 4. Seleccionar, de las otras variables, una que el equipo considere que podría ser útil para predecir la clase EN, justificando bien esta selección.
# Para 3. -> Traemos las ocho variables predictoras del ejercicio anterior
# Para 4 -> Escogemos el peso como predictor para el modelo de RLogS ya que el peso se relaciona fuertemente con el IMC, el cual se usa para determinar sobrepeso
entrenamiento <- entrenamiento %>% select(EN, Biacromial.diameter, Calf.Maximum.Girth, Chest.depth, Bicep.Girth, Bitrochanteric.diameter, Age, Elbows.diameter, Hip.Girth, Weight)
prueba <- entrenamiento %>% select(EN, Biacromial.diameter, Calf.Maximum.Girth, Chest.depth, Bicep.Girth, Bitrochanteric.diameter, Age, Elbows.diameter, Hip.Girth, Weight)
# 5. Usando el entorno R y paquetes estándares, construir un modelo de regresión logística con el predictor seleccionado en el paso anterior y utilizando de la muestra obtenida.
# Usamos el modelo de regresión logistica simple con predictor peso y data de entrenamiento del punto anterior
rlogs <- glm(EN ~ Weight, data = entrenamiento,
family = binomial(link = "logit"))
summary(rlogs)
# Evaluamos la calidad predictiva del modelo anterior, con umbral de 0.5
umbral <- 0.5
probabilidades <- predict(rlogs, prueba, type = "response")
predicciones <- sapply(probabilidades,
function (p) ifelse (p >= umbral, "Sobrepeso", "No sobrepeso"))
predicciones <- factor(predicciones, levels = levels(prueba[["EN"]]))
confusionMatrix(predicciones, prueba[["EN"]])
# Podemos ver que el tiene una buena capacidad predictiva, con una exactitud de
# 80,0%, sensibilidad de 83,33% y especificidad de 76,67%.
# 6. Usando herramientas estándares para la exploración de modelos del entorno R, buscar entre dos y cinco predictores de entre las variables seleccionadas al azar, recordadas en el punto 3, para agregar al modelo obtenido en el paso 5.
# Seleccionamos los mejores predictores para el modelo de regresión lineal múltiple usando el método de todos los subconjuntos.
rlogm.inicial <- regsubsets(EN ~ ., data = entrenamiento, nbest = 1, nvmax = 5,
method = "exhaustive")
plot(rlogm.inicial)
# De acuerdo a la exploración de todos los subconjuntos, se obtiene que el mejor modelo
# entre 2 y 5 variables usa como predictores Calf.Maximum.Girth, Chest.depth, Bicep.Girth, Elbows.diameter y Hip.Girth
data_glm2 <- entrenamiento %>% select(predictores)
rlogm.inicial <- regsubsets(EN ~ ., data = data_glm2, nbest = 1, nvmax = 5,
method = "exhaustive")
library(caret)
library(pROC)
library(tidyverse)
data <- read.csv2("EP09 Datos.csv", stringsAsFactors = TRUE) # Se lee el archivo
IMC <- data$Weight / ((data$Height / 100) ** 2)  # Se pasa la altura de centimetros a metros y se calcula IMC
EN <- ifelse(IMC > 25, 1, 0) # Se inicia un vector dicotomico  (1: Sobrepeso, 0: No sobrepeso)
data <- data.frame(data, EN)
hombres <- subset(data, Gender == 1)
hombres$Gender <- NULL
sobrepeso <- subset(hombres, EN == 1)
noSobrepeso <- subset(hombres, EN == 0)
set.seed(1667) # Se define la semilla según el rut del miembro mayor (ultimos 4 digitos antes del digito verificador)
# Se toma una muestra de 90 con 45 en sobrepeso y 45 que no
muestra <- merge(sample_n(sobrepeso, 45), sample_n(noSobrepeso, 45), all = TRUE)
sobrepeso <- subset(muestra, EN == 1)
noSobrepeso <- subset(muestra, EN == 0)
# Se obtiene una submuestra de 60 con 30 en sobrepeso y 30 que no para el entrenamiento del modelo
entrenamiento <- merge(sample_n(sobrepeso, 30), sample_n(noSobrepeso, 30), all = TRUE)
# De la muestra original (de 90) se toman los datos restantes (que no son destinados al entrenamiento), para usarlos para la proxima evaluacion del modelo
evaluacion <- anti_join(muestra, entrenamiento, by = names(muestra))
predictores <- c("Biacromial.diameter", "Calf.Maximum.Girth", "Chest.depth", "Bicep.Girth", "Bitrochanteric.diameter", "Age", "Elbows.diameter", "Hip.Girth")
respuesta <- entrenamiento[["EN"]]
entrenamiento[["EN"]] <- NULL
matriz <- entrenamiento %>% select(-any_of(predictores))
correlacion <- cor(matriz, y = respuesta)
correlacion
mejor <- which(correlacion == max(abs(correlacion)))
predictor <- rownames(correlacion)[mejor]
predictor
modelo_1 <- glm(respuesta ~ Navel.Girth, family = binomial(link = "logit"), data = entrenamiento)
data_glm2 <- entrenamiento %>% select(predictores)
rlogm.inicial <- regsubsets(EN ~ ., data = data_glm2, nbest = 1, nvmax = 5,
method = "exhaustive")
data_glm2 <- entrenamiento %>% select(predictores)
# Seleccionar mejores predictores para modelo de regresión lineal múltiple
# usando el método de todos los subconjuntos.
modelo_2 <- regsubsets(EN ~ ., data = data_glm2, nbest = 1, nvmax = 5,
method = "exhaustive")
View(data_glm2)
data_glm2 <- entrenamiento %>% select(predictores)
# Seleccionar mejores predictores para modelo de regresión lineal múltiple
# usando el método de todos los subconjuntos.
modelo_2 <- regsubsets(EN ~ ., data = data_glm2, nbest = 1, nvmax = 5,
method = "exhaustive")
library(caret)
library(pROC)
library(leaps)
library(tidyverse)
data_glm2 <- entrenamiento %>% select(predictores)
length(data_glm2$Biacromial.diameter)
# Seleccionar mejores predictores para modelo de regresión lineal múltiple
# usando el método de todos los subconjuntos.
modelo_2 <- regsubsets(EN ~ ., data = data_glm2, nbest = 1, nvmax = 5,
method = "exhaustive")
data_glm2 <- entrenamiento %>% select(predictores)
length(data_glm2)
# Seleccionar mejores predictores para modelo de regresión lineal múltiple
# usando el método de todos los subconjuntos.
modelo_2 <- regsubsets(EN ~ ., data = data_glm2, nbest = 1, nvmax = 5,
method = "exhaustive")
View(data_glm2)
data_glm2 <- entrenamiento %>% select(predictores)
exists(data_glm2)
data_glm2 <- entrenamiento %>% select(predictores)
exists(data_glm2$Biacromial.diameter)
data_glm2 <- entrenamiento %>% select(predictores)
"Biacromial.diameter" %in% colnames(data_glm2)
# Seleccionar mejores predictores para modelo de regresión lineal múltiple
# usando el método de todos los subconjuntos.
modelo_2 <- regsubsets(EN ~ ., data = data_glm2, nbest = 1, nvmax = 5,
method = "exhaustive")
View(data_glm2)
library(tidyverse)
library(pROC)
library(caret)
library(leaps)
library(car)
# 1. Definir la semilla a utilizar, que corresponde a los últimos cuatro dígitos del RUN (sin considerar el dígito verificador) del integrante de mayor edad del equipo.
set.seed(1667)
datos <- read.csv2("EP09 Datos.csv")
# 2. Seleccionar una muestra de 90 mujeres (si la semilla es un número par) o 90 hombres (si la semilla es impar), asegurando que la mitad tenga estado nutricional “sobrepeso” y la otra mitad “no sobrepeso” en cada caso. Dividir esta muestra en dos conjuntos: los datos de 60 personas (30 con EN “sobrepeso”) para utilizar en la construcción de los modelos y 30 personas (15 con EN “sobrepeso”) para poder evaluarlos.
# Variable IMC -> Kilogramos / Estatura^2 (Estatura en metros, en csv está en centimetros)
IMC <- datos[["Weight"]] / ((datos[["Height"]] / 100) ** 2)
# Construimos la variable dicotómica EN (Estado Nutricional) para sobrepeso (IMC >= 25) y no sobrepeso (IMC < 25)
EN <- rep("Sobrepeso", length(IMC))
EN[IMC < 25] <- "No sobrepeso"
EN <- factor(EN)
datos <- cbind(EN, datos)
# Obtenemos solo los hombres y eliminamos la columna Gender (inutil de acá en adelante)
datos <- datos %>% filter(datos$Gender == 1)
datos[["Gender"]] <- NULL
# Obtenemos mitad sobrepeso y mitad no sobrepeso (45 y 45, total 90)
sobrepeso <- filter(datos, EN == "Sobrepeso")
sobrepeso <- sample_n(sobrepeso, 45, replace = FALSE)
no_sobrepeso <- datos %>% filter(EN == "No sobrepeso")
no_sobrepeso <- sample_n(no_sobrepeso, 45, replace = FALSE)
# Separamos por conjuntos de entrenamiento y de prueba
sobrepeso_1 <- sample.int(nrow(sobrepeso), 30, replace = FALSE)
no_sobrepeso_1 <- sample.int(nrow(no_sobrepeso), 30, replace = FALSE)
entrenamiento_sobrepeso <- sobrepeso[sobrepeso_1,] # 30 sobrepeso
entrenamiento_no_sobrepeso <- no_sobrepeso[no_sobrepeso_1,] # 30 no sobrepeso
prueba_sobrepeso <- sobrepeso[-sobrepeso_1,] # restante (15) sobrepeso
prueba_no_sobrepeso <- no_sobrepeso[-no_sobrepeso_1,] # restante (15) no sobrepeso
entrenamiento <- rbind(entrenamiento_sobrepeso, entrenamiento_no_sobrepeso) # total 60
prueba <- rbind(prueba_sobrepeso, prueba_no_sobrepeso) # total 30
# 3. Recordar las ocho posibles variables predictoras seleccionadas de forma aleatoria en el ejercicio anterior.
# 4. Seleccionar, de las otras variables, una que el equipo considere que podría ser útil para predecir la clase EN, justificando bien esta selección.
# Para 3. -> Traemos las ocho variables predictoras del ejercicio anterior
# Para 4 -> Escogemos el peso como predictor para el modelo de RLogS ya que el peso se relaciona fuertemente con el IMC, el cual se usa para determinar sobrepeso
entrenamiento <- entrenamiento %>% select(EN, Biacromial.diameter, Calf.Maximum.Girth, Chest.depth, Bicep.Girth, Bitrochanteric.diameter, Age, Elbows.diameter, Hip.Girth, Weight)
prueba <- entrenamiento %>% select(EN, Biacromial.diameter, Calf.Maximum.Girth, Chest.depth, Bicep.Girth, Bitrochanteric.diameter, Age, Elbows.diameter, Hip.Girth, Weight)
# 5. Usando el entorno R y paquetes estándares, construir un modelo de regresión logística con el predictor seleccionado en el paso anterior y utilizando de la muestra obtenida.
# Usamos el modelo de regresión logistica simple con predictor peso y data de entrenamiento del punto anterior
rlogs <- glm(EN ~ Weight, data = entrenamiento,
family = binomial(link = "logit"))
summary(rlogs)
# Evaluamos la calidad predictiva del modelo anterior, con umbral de 0.5
umbral <- 0.5
probabilidades <- predict(rlogs, prueba, type = "response")
predicciones <- sapply(probabilidades,
function (p) ifelse (p >= umbral, "Sobrepeso", "No sobrepeso"))
predicciones <- factor(predicciones, levels = levels(prueba[["EN"]]))
confusionMatrix(predicciones, prueba[["EN"]])
# Podemos ver que el tiene una buena capacidad predictiva, con una exactitud de
# 80,0%, sensibilidad de 83,33% y especificidad de 76,67%.
# 6. Usando herramientas estándares para la exploración de modelos del entorno R, buscar entre dos y cinco predictores de entre las variables seleccionadas al azar, recordadas en el punto 3, para agregar al modelo obtenido en el paso 5.
# Seleccionamos los mejores predictores para el modelo de regresión lineal múltiple usando el método de todos los subconjuntos.
rlogm.inicial <- regsubsets(EN ~ ., data = entrenamiento, nbest = 1, nvmax = 5,
method = "exhaustive")
plot(rlogm.inicial)
# De acuerdo a la exploración de todos los subconjuntos, se obtiene que el mejor modelo
# entre 2 y 5 variables usa como predictores Calf.Maximum.Girth, Chest.depth, Bicep.Girth, Elbows.diameter y Hip.Girth
data_glm2 <- entrenamiento %>% select(predictores)
# Seleccionar mejores predictores para modelo de regresión
# usando el método de todos los subconjuntos.
modelo_2 <- regsubsets(EN ~ ., data = data_glm2, nbest = 1, nvmax = 5,
method = "exhaustive")
umbral <- 0.5
probs_1 <- predict(modelo_1, evaluacion, type = "response")
library(caret)
library(pROC)
library(leaps)
library(tidyverse)
library(caret)
library(pROC)
library(leaps)
library(tidyverse)
library(ggpubr)
library(car)
library(caret)
library(leaps)
library(tidyverse)
datos = read.csv2("EP09 Datos.csv")
# Se define una semilla con los últiimos 4 digitos del RUN de
# un miembro de equipo con 21 años
set.seed(4346)
mujeres = datos %>% filter(Gender == 0) %>% sample_n(50, replace = F)
# Se hace nula la columna de genero ya que no es necesaria
mujeres[["Gender"]] = NULL
#Conjunto entrenamiento y prueba
n <- nrow(mujeres)
n_entrenamiento <- floor(0.9 * n) # Utilizaremos el 90% de las 50 muestras
m <- sample.int(n = n, size = n_entrenamiento, replace = FALSE)
datos_entrenamiento <- mujeres[m,]
datos_prueba <- mujeres[-m,]
